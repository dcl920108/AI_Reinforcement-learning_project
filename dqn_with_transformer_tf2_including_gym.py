# -*- coding: utf-8 -*-
"""updated_DQN_with_Transformer_TF2_including_Gym.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Nw2MPnflwOD1YBU0PGC95Zu3iRJOCTS

# Deep Q-Network with Transformer

This notebook contains an updated version of the Deep Q-Network (DQN) which incorporates a Transformer attention mechanism.
"""

import gym

import tensorflow as tf
from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Input
from tensorflow.keras.models import Model

import tensorflow as tf
from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential(
            [Dense(ff_dim, activation="relu"), Dense(embed_dim),]
        )
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

import tensorflow as tf
from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Input
from tensorflow.keras.models import Model

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential([
            Dense(ff_dim, activation="relu"), Dense(embed_dim),
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, inputs, training=False):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class QNetwork(Model):
    def __init__(self, state_dim, action_size, embed_dim=128, num_heads=4, ff_dim=256):
        super(QNetwork, self).__init__()
        self.state_input = Input(shape=(state_dim,))
        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
        self.state_embedding = Dense(embed_dim, activation='relu')(self.state_input)
        self.transformed_state = self.transformer_block(self.state_embedding)
        self.q_values = Dense(action_size, activation=None)(self.transformed_state)

    def call(self, inputs):
        x = self.state_embedding(inputs)
        x = self.transformer_block(x)
        return self.q_values(x)

env_name = 'CartPole-v0'
env = gym.make(env_name)
print('Observation space:', env.observation_space)
print('Action space:', env.action_space)

state_dim = env.observation_space.shape[0]
action_size = env.action_space.n
q_network = QNetwork(state_dim, action_size)
# Add more initialization as necessary
